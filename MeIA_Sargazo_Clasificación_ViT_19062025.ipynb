{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP6ty8Zlr9vBKwe4A8TnPES",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gabrielcarcedo/SargazoClassification_ViT/blob/main/MeIA_Sargazo_Clasificaci%C3%B3n_ViT_19062025.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uh2J41JG7c8S"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from google.colab import drive\n",
        "import torch\n",
        "from transformers import ViTImageProcessor\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import torch.nn as nn\n",
        "from transformers import ViTForImageClassification\n",
        "from torch.optim import AdamW\n",
        "import time\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import cv2\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Gbc5pWYZ7fma"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Revisar bien el path a la carpeta de Drive"
      ],
      "metadata": {
        "id": "Rg3UKX0-7iT9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cd drive/MyDrive/MeIA Sargazo Dataset/"
      ],
      "metadata": {
        "id": "5nJ9sFYY7fjw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = pd.read_csv('labels/labels_augmented.csv')\n",
        "df_test = pd.read_csv('labels/test.csv')\n",
        "\n",
        "images_list = os.listdir('resized_images')\n",
        "\n",
        "images_train = df_train['image_name'].tolist()\n",
        "images_test = df_test['image_name'].tolist()\n",
        "\n",
        "images_train = ['resized_images/' + image for image in images_train]\n",
        "images_test = ['resized_images/' + image for image in images_test]\n",
        "\n",
        "df_test['label_num'] = np.zeros(len(df_test))\n",
        "\n",
        "images_train_label = df_train[['image_name', 'label_num']].values.tolist()\n",
        "images_test_label = df_test[['image_name', 'label_num']].values.tolist()"
      ],
      "metadata": {
        "id": "bY6KySww7fhM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FilenameMappedDataset(Dataset):\n",
        "    def __init__(self, image_paths, filename_label_pairs, transform=None):\n",
        "        self.image_paths = image_paths\n",
        "        self.transform = transform\n",
        "\n",
        "        # Crear un diccionario tipo: {'ID_0001.png': 0, 'ID_0002.jpg': 1, ...}\n",
        "        self.label_map = {filename: label for filename, label in filename_label_pairs}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.image_paths[idx]\n",
        "        filename = os.path.basename(img_path)\n",
        "        label = self.label_map[filename]  # Busca la clase asociada a este filename\n",
        "\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label"
      ],
      "metadata": {
        "id": "IJUxhaRm7fel"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processor = ViTImageProcessor.from_pretrained('google/vit-base-patch16-224-in21k')\n",
        "\n",
        "transform_fn = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=processor.image_mean, std=processor.image_std)\n",
        "])"
      ],
      "metadata": {
        "id": "JmAXFx6_7fbw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "images_train, images_val, images_train_label, images_val_label = train_test_split(images_train, images_train_label, test_size=0.2, random_state=250)"
      ],
      "metadata": {
        "id": "TELIpBoq7zk2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = FilenameMappedDataset(images_train, images_train_label, transform=transform_fn)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "val_dataset = FilenameMappedDataset(images_val, images_val_label, transform=transform_fn)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "test_dataset = FilenameMappedDataset(images_test, images_test_label, transform=transform_fn)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "vgqvskbb7ziU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuración\n",
        "num_epochs = 10\n",
        "patience = 5\n",
        "learning_rate = 2e-6\n",
        "num_classes = 5\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "Y3R-zT-K7zfq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Métricas\n",
        "train_stats, val_stats = [], []\n",
        "\n",
        "#fecha = time.strftime(\"%Y_%m_%d\")\n",
        "fecha = '2025_06_18'\n",
        "checkpoint_dir = f\"ViT_checkpoints_{fecha}\"\n",
        "os.makedirs(checkpoint_dir, exist_ok=True)"
      ],
      "metadata": {
        "id": "dITTOTjX7zdH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = ViTForImageClassification.from_pretrained(\n",
        "        'google/vit-base-patch16-224-in21k',\n",
        "        num_labels=num_classes\n",
        "    )\n",
        "# Ruta del mejor modelo\n",
        "best_model_path = os.path.join(checkpoint_dir, f\"ViT_best_model_Luis.pth\")\n",
        "model.load_state_dict(torch.load(best_model_path, map_location=device))\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "# Optimizador y función de pérdida\n",
        "optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
        "criterion = nn.BCEWithLogitsLoss()"
      ],
      "metadata": {
        "id": "Eg2dgJ1E7fZG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Entrenamiento"
      ],
      "metadata": {
        "id": "jdvgiZel8oRa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_val_acc, patience_counter, best_val_f1 = 0.0, 0, 0.0\n",
        "for epoch in range(num_epochs):\n",
        "    # ----- Entrenamiento -----\n",
        "    epoch_train_start = time.time()\n",
        "    model.train()\n",
        "\n",
        "    running_loss, correct, total, running_sensitivity, running_specificity = 0.0, 0, 0, 0.0, 0.0\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        # Convert labels to one-hot encoding\n",
        "        labels_one_hot = torch.zeros(labels.size(0), num_classes).to(device)\n",
        "        labels_one_hot.scatter_(1, labels.unsqueeze(1), 1)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images).logits\n",
        "        loss = criterion(outputs, labels_one_hot) # Use one-hot encoded labels\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        tp = ((predicted == labels) & (labels == 1)).sum().item()\n",
        "        tn = ((predicted == labels) & (labels == 0)).sum().item()\n",
        "        fp = ((predicted != labels) & (labels == 0)).sum().item()\n",
        "        fn = ((predicted != labels) & (labels == 1)).sum().item()\n",
        "        running_sensitivity += tp / (tp + fn + 1e-8)\n",
        "        running_specificity += tn / (tn + fp + 1e-8)\n",
        "        total += labels.size(0)\n",
        "\n",
        "    train_loss = running_loss / total\n",
        "    train_acc = correct / total\n",
        "    train_sensitivity = running_sensitivity / total\n",
        "    train_specificity = running_specificity / total\n",
        "    train_time = time.time() - epoch_train_start\n",
        "\n",
        "    # ----- Validación -----\n",
        "    epoch_val_start = time.time()\n",
        "    model.eval()\n",
        "\n",
        "    val_loss, val_correct, val_total, val_sensitivity, val_specificity, val_f1 = 0.0, 0, 0, 0.0, 0.0, 0.0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            # Convert labels to one-hot encoding\n",
        "            labels_one_hot = torch.zeros(labels.size(0), num_classes).to(device)\n",
        "            labels_one_hot.scatter_(1, labels.unsqueeze(1), 1)\n",
        "\n",
        "            outputs = model(images).logits\n",
        "            loss = criterion(outputs, labels_one_hot) # Use one-hot encoded labels\n",
        "\n",
        "            val_loss += loss.item() * images.size(0)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            val_correct += (predicted == labels).sum().item()\n",
        "            tp = ((predicted == labels) & (labels == 1)).sum().item()\n",
        "            tn = ((predicted == labels) & (labels == 0)).sum().item()\n",
        "            fp = ((predicted != labels) & (labels == 0)).sum().item()\n",
        "            fn = ((predicted != labels) & (labels == 1)).sum().item()\n",
        "            val_sensitivity += tp / (tp + fn + 1e-8)\n",
        "            val_specificity += tn / (tn + fp + 1e-8)\n",
        "            val_total += labels.size(0)\n",
        "            val_f1 += 2 * tp / (2 * tp + fp + fn + 1e-8)\n",
        "\n",
        "    val_loss /= val_total\n",
        "    val_acc = val_correct / val_total\n",
        "    val_sensitivity /= val_total\n",
        "    val_specificity /= val_total\n",
        "    val_time = time.time() - epoch_val_start\n",
        "    val_f1 /= val_total\n",
        "\n",
        "    print(f\"Epoch {epoch+1}: Train Loss={train_loss:.4f}, Acc={train_acc:.4f}, \"\n",
        "              f\"Val Loss={val_loss:.4f}, Acc={val_acc:.4f}\")\n",
        "\n",
        "    # Guardar si mejora la validación\n",
        "    if best_val_f1 < val_f1:\n",
        "        best_val_f1 = val_f1\n",
        "        torch.save(model.state_dict(), os.path.join(checkpoint_dir, f\"ViT_best_model_19062025.pth\"))\n",
        "        print(f\"Mejor modelo guardado en epoch {epoch+1} con val acc = {val_acc:.4f}\")\n",
        "        patience_counter = 0\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "        if patience_counter >= patience:\n",
        "            print(f\"Early stopping en epoch {epoch+1} con val acc = {val_acc:.4f}\")\n",
        "            break\n",
        "\n",
        "    # Registrar métricas\n",
        "    train_stats.append([epoch+1, train_loss, train_acc, train_sensitivity, train_specificity, train_time])\n",
        "    val_stats.append([epoch+1, val_loss, val_acc, val_sensitivity, val_specificity, val_time, val_f1])\n",
        "\n",
        "# Guardar métricas\n",
        "train_df = pd.DataFrame(train_stats, columns=['Epoch', 'Train_Loss', 'Train_Acc', 'Train_Sensitivity', 'Train_Specificity', 'Train_Time'])\n",
        "val_df = pd.DataFrame(val_stats, columns=['Epoch', 'Val_Loss', 'Val_Acc', 'Val_Sensitivity', 'Val_Specificity', 'Val_Time', 'Val_f1'])\n",
        "\n",
        "train_df.to_csv(os.path.join(checkpoint_dir, 'ViT_train_stats_Luis.csv'), index=False)\n",
        "val_df.to_csv(os.path.join(checkpoint_dir, 'ViT_val_stats_Luis.csv'), index=False)\n",
        "\n",
        "print(\"Entrenamiento finalizado. Modelo óptimo guardado como best_vit_model.pth\")"
      ],
      "metadata": {
        "id": "Q293Mn7I8iqW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Validación"
      ],
      "metadata": {
        "id": "nLED_hsP8pkD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fecha = '2025_06_18'\n",
        "checkpoint_dir = f\"ViT_checkpoints_{fecha}\"\n",
        "\n",
        "# Ruta del mejor modelo\n",
        "best_model_path = os.path.join(checkpoint_dir, f\"ViT_best_model_Luis.pth\")\n",
        "\n",
        "# Cargar modelo\n",
        "model = ViTForImageClassification.from_pretrained(\n",
        "    'google/vit-base-patch16-224-in21k',\n",
        "    num_labels=num_classes\n",
        ")\n",
        "model.load_state_dict(torch.load(best_model_path, map_location=device))\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "y_true = []\n",
        "y_pred = []\n",
        "\n",
        "# test_loader debe estar definido previamente\n",
        "for images, labels in val_loader:\n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(images)\n",
        "        probs = F.softmax(outputs.logits, dim=1)\n",
        "        preds = torch.argmax(probs, dim=1)\n",
        "\n",
        "    y_true.extend(labels.cpu().numpy())\n",
        "    y_pred.extend(preds.cpu().numpy())\n",
        "\n",
        "print(\"\\n--- Classification Report ---\")\n",
        "print(classification_report(y_true, y_pred))\n",
        "\n",
        "# Matriz de confusión\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "disp.plot(cmap=plt.cm.Blues)\n",
        "plt.title(\"Matriz de Confusión - Validación Set\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "aoF9sXSo8inl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test"
      ],
      "metadata": {
        "id": "_OjXgqeq83Rj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = pd.read_csv('new_version/labels/labels.csv')\n",
        "df_test = pd.read_csv('new_version/labels/test.csv')\n",
        "\n",
        "images_list = os.listdir('new_version/images')\n",
        "\n",
        "images_train = df_train['image_name'].tolist()\n",
        "images_train = ['new_version/resized_images/' + image for image in images_train]\n",
        "\n",
        "images_test = df_test['image_name'].tolist()\n",
        "images_test_paths = ['new_version/resized_images/' + image for image in images_test]"
      ],
      "metadata": {
        "id": "28sOE2ez8ik2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_dict = {'nada':0, 'bajo':1, 'moderado':2, 'abundante':3, 'excesivo':4}\n",
        "df_train['label_num'] = df_train['label'].map(label_dict)\n",
        "images_train_label = df_train[['image_name', 'label_num']].values.tolist()\n",
        "\n",
        "df_test['label_num'] = np.zeros(len(df_test))\n",
        "images_test_label = df_test[['image_name', 'label_num']].values.tolist()\n",
        "\n",
        "train_dataset = FilenameMappedDataset(images_train, images_train_label, transform=transform_fn)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "test_dataset = FilenameMappedDataset(images_test_paths, images_test_label, transform=transform_fn)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "T2zq4VNy8iiJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fecha = '2025_06_18'\n",
        "checkpoint_dir = f\"ViT_checkpoints_{fecha}\"\n",
        "num_classes = 5\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Ruta del mejor modelo\n",
        "best_model_path = os.path.join(checkpoint_dir, f\"ViT_best_model_Luis.pth\")\n",
        "\n",
        "# Cargar modelo\n",
        "model = ViTForImageClassification.from_pretrained(\n",
        "    'google/vit-base-patch16-224-in21k',\n",
        "    num_labels=num_classes\n",
        ")\n",
        "model.load_state_dict(torch.load(best_model_path, map_location=device))\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "y_true = []\n",
        "y_pred = []\n",
        "\n",
        "# test_loader debe estar definido previamente\n",
        "for images, labels in test_loader:\n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(images)\n",
        "        probs = F.softmax(outputs.logits, dim=1)\n",
        "        preds = torch.argmax(probs, dim=1)\n",
        "\n",
        "    y_true.extend(labels.cpu().numpy())\n",
        "    y_pred.extend(preds.cpu().numpy())\n",
        "\n",
        "y_true = np.array(y_true)\n",
        "y_pred = np.array(y_pred)\n",
        "\n",
        "for img1, img2 in zip(images_test, df_test['image_name'].tolist()):\n",
        "  if img1.split('/')[-1]!= img2:\n",
        "    print('ERROR', img1)"
      ],
      "metadata": {
        "id": "Vsu_wAAG8iez"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_prediction = pd.DataFrame({'image_name': df_test['image_name'].tolist(), 'label': y_pred})\n",
        "df_prediction.head()"
      ],
      "metadata": {
        "id": "cxpG5OkE7fWW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_dict = {'nada':0, 'bajo':1, 'moderado':2, 'abundante':3, 'excesivo':4}\n",
        "label_dict_inv = {0:'nada', 1:'bajo', 2:'moderado', 3:'abundante', 4:'excesivo'}\n",
        "df_prediction['label'] = df_prediction['label'].map(label_dict_inv)\n",
        "df_prediction.head()"
      ],
      "metadata": {
        "id": "uC2AxHA29VDm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "csv_path = 'ViT_predictions_19062025.csv'\n",
        "df_prediction.to_csv(csv_path, index=False)"
      ],
      "metadata": {
        "id": "IhChe3kj9VA-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}